#!/usr/bin/env python3
"""
MVP Chunking Analysis: Validate Gold Standard Integration
Analyze the chunks generated by MVP with Gold Standard chunker
"""

from gold_standard_chunker import GoldStandardChunker
from smart_chunking import ProgressiveContentFetcher

def analyze_mvp_chunks():
    """Analyze chunks generated by MVP system for the Substack article"""

    print("ğŸ” MVP CHUNKING ANALYSIS WITH GOLD STANDARD")
    print("=" * 70)

    # Initialize the same chunker setup as MVP
    chunker = GoldStandardChunker(target_size=250)  # MVP uses 250 char target
    content_fetcher = ProgressiveContentFetcher(chunker)

    # Test URL
    url = "https://sundaylettersfromsam.substack.com/p/the-attention-economy-is-inverting?triedRedirect=true"

    print(f"ğŸ“° Testing URL: {url}")
    print(f"ğŸ¯ Chunker: Gold Standard (250 char target)")

    try:
        # Fetch and chunk the same way MVP does
        print(f"\nâ³ Fetching and chunking content...")
        chunks = list(content_fetcher.fetch_and_chunk_progressive(url))

        if not chunks:
            print("âŒ No chunks generated")
            return

        # Re-chunk using natural speech boundaries (as MVP does)
        print(f"ğŸ”„ Re-chunking with natural speech boundaries...")
        full_text = ' '.join(chunks)
        final_chunks = chunker.gold_standard_chunk_text(full_text)

        # Apply 1000 character limit (as in our test)
        limited_chunks = []
        total_chars = 0
        for chunk in final_chunks:
            if total_chars + len(chunk) <= 1000:
                limited_chunks.append(chunk)
                total_chars += len(chunk)
            else:
                remaining = 1000 - total_chars
                if remaining > 50:  # Only add if meaningful chunk remains
                    limited_chunks.append(chunk[:remaining].rstrip())
                break

        print(f"\nğŸ“Š CHUNKING RESULTS")
        print("=" * 50)
        print(f"Initial chunks from fetcher: {len(chunks)}")
        print(f"Final chunks after Gold Standard processing: {len(final_chunks)}")
        print(f"Limited chunks (1000 chars): {len(limited_chunks)}")
        print(f"Total characters: {sum(len(c) for c in limited_chunks)}")

        print(f"\nğŸ” TTS QUALITY ANALYSIS")
        print("=" * 50)

        word_cutoffs = 0
        spacing_issues = 0
        natural_boundaries = 0

        for i, chunk in enumerate(limited_chunks):
            chunk_clean = chunk.strip()

            # Check for natural sentence endings
            if chunk_clean.endswith(('.', '!', '?', ':', ';')):
                natural_boundaries += 1

            # Check for word cutoffs
            if i < len(limited_chunks) - 1:  # Not the last chunk
                current_ends_alpha = chunk_clean[-1:].isalpha()
                next_starts_alpha = limited_chunks[i+1].strip()[0:1].isalpha()
                if current_ends_alpha and next_starts_alpha:
                    word_cutoffs += 1
                    print(f"   âš ï¸ Potential word cutoff between chunks {i+1} and {i+2}")

            # Check for spacing issues
            if '  ' in chunk:
                spacing_issues += 1

        print(f"\nâœ… QUALITY METRICS")
        print("=" * 30)
        print(f"ğŸµ Word cutoffs: {word_cutoffs} (ZERO = PERFECT)")
        print(f"ğŸµ Spacing issues: {spacing_issues} (ZERO = PERFECT)")
        print(f"ğŸµ Natural boundaries: {natural_boundaries}/{len(limited_chunks)} ({100*natural_boundaries/len(limited_chunks):.1f}%)")

        if word_cutoffs == 0 and spacing_issues == 0:
            print("ğŸ† PERFECT TTS QUALITY: Gold Standard chunker working perfectly!")
        else:
            print("âš ï¸ Some quality issues detected")

        print(f"\nğŸ“ CHUNK DETAILS")
        print("=" * 50)
        for i, chunk in enumerate(limited_chunks, 1):
            chunk_preview = chunk.strip()[:80] + "..." if len(chunk) > 80 else chunk.strip()
            boundary_type = "Natural" if chunk.strip().endswith(('.', '!', '?', ':', ';')) else "Split"
            print(f"Chunk {i} ({len(chunk):3d} chars, {boundary_type}): {chunk_preview}")

        return limited_chunks

    except Exception as e:
        print(f"âŒ Error: {e}")
        return []

if __name__ == "__main__":
    chunks = analyze_mvp_chunks()

    if chunks:
        print(f"\nğŸŠ SUCCESS: Gold Standard chunker integrated and working!")
        print(f"ğŸµ MVP now uses our 100% test pass rate chunker for optimal TTS quality!")
    else:
        print(f"\nâŒ Integration issue detected")